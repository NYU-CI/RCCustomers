{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Linkages\n",
    "This notebook generates potential linkages between datasets and publications by running full text searches through various APIs. The search terms used are dataset `titles` (dataset `alt_titles` can also be used, though they are not here). NOAA datasets are used in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scholapi' from '/Users/sophierand/RCCustomers/scholapi.py'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import importlib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "import scholapi\n",
    "importlib.reload(scholapi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and instance of the scholapi class from the richcontext.scholapi library (`scholapi`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "schol = scholapi.ScholInfraAPI(config_file=\"rc.cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in datasets and filter to those for a specific client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/sophierand/RCDatasets/datasets.json') as json_file:\n",
    "    datasets = json.load(json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_datasets = [d for d in datasets if d['provider'] in [\"provider-285\", \"provider-150\",\"provider-287\",\"provider-295\",\"dataset-627\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Text Search Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_api_results(n,api_name,nresults):\n",
    "    s_term = n[\"title\"]\n",
    "    s_id = n[\"id\"]\n",
    "\n",
    "    if api_name == \"openaire\":\n",
    "        search_results = schol.openaire.full_text_search(search_term = s_term, nresults = nresults)\n",
    "\n",
    "    if api_name == \"pubmed\":\n",
    "        search_results = schol.pubmed.full_text_search(search_term = s_term, nresults = nresults)\n",
    "    \n",
    "    if api_name == \"dimensions\":\n",
    "        search_results = schol.dimensions.full_text_search(search_term = s_term,nresults = nresults)\n",
    "\n",
    "    if search_results:\n",
    "        if isinstance(search_results,list) and len(search_results) > 0:\n",
    "            meta_list = []\n",
    "            for m in search_results:\n",
    "                if api_name == \"openaire\":\n",
    "                    meta = schol.openaire.parse_oa(result = m)\n",
    "                if api_name == \"pubmed\":\n",
    "                    meta = schol.pubmed.parse_pubmed(result = m)\n",
    "                if api_name == \"dimensions\":\n",
    "                    meta = schol.dimensions.parse_dimensions(result = m)\n",
    "                if meta:\n",
    "                    meta_list.append(meta)\n",
    "\n",
    "\n",
    "            return meta_list\n",
    "    elif not search_results:\n",
    "        print('no results for search term {} from API {}'.format(s_term, api_name))\n",
    "        return None\n",
    "\n",
    "def convert_md_list(n,meta_list):\n",
    "    s_term = n[\"title\"]\n",
    "    s_id = n[\"id\"]\n",
    "    if len(meta_list) > 0:\n",
    "        df = pd.DataFrame(meta_list)\n",
    "        df[\"authors\"] = df['authors'].apply(lambda x:', '.join(x) if isinstance(x,list) else x)\n",
    "        df['search_term'] = s_term\n",
    "        df['dataset_id'] = s_id\n",
    "        return df\n",
    "\n",
    "def export_linkages(df,s_term,api_name):\n",
    "    folder_name = \"/Users/sophierand/RichContextMetadata/metadata/{}_{}_{}\".format(datetime.date.today().strftime(\"%Y%m%d\"),api_name,re.sub(\" \",\"\",s_term))\n",
    "    path_name = folder_name + \"/{}.csv\".format(re.sub(\" \",\"\",s_term))\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    df.to_csv(path_name,index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the below cells will create exports in the RichContextMetadata/metadata folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = schol.openaire.full_text_search(search_term = \"US Interagency Elevation Inventory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in noaa_datasets:\n",
    "    s_term = n[\"title\"]\n",
    "    s_id = n[\"id\"]\n",
    "    meta_list = parse_api_results(n = n, api_name = 'openaire',nresults = 100)\n",
    "    if meta_list:\n",
    "        df = convert_md_list(n = n, meta_list = meta_list)\n",
    "        if df is not None and len(df) > 0:\n",
    "            export_linkages(df = df, s_term = s_term ,api_name = 'openaire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_full = schol.pubmed.full_text_search(search_term = \"Sea Level Rise Inundation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in noaa_datasets:\n",
    "    s_term = n[\"title\"]\n",
    "    s_id = n[\"id\"]\n",
    "    meta_list = parse_api_results(n = n, api_name = 'pubmed',nresults = 100)\n",
    "    if meta_list:\n",
    "        df = convert_md_list(n = n, meta_list = meta_list)\n",
    "        if df is not None and len(df) > 0:\n",
    "            export_linkages(df = df, s_term = s_term ,api_name = 'pubmed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in noaa_datasets:\n",
    "    s_term = n[\"title\"]\n",
    "    s_id = n[\"id\"]\n",
    "    meta_list = parse_api_results(n = n, api_name = 'dimensions',nresults = 100)\n",
    "    if meta_list:\n",
    "        df = convert_md_list(n = n, meta_list = meta_list)\n",
    "        if df is not None and len(df) > 0:\n",
    "            export_linkages(df = df, s_term = s_term ,api_name = 'dimensions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
